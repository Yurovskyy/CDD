{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXm7WdGkNcaawaXZQz7Y5v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yurovskyy/CDD/blob/main/TrabalhoGovernanca.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Formaliza√ß√£o do problema\n",
        "\n",
        "## 1.1. Contextualiza√ß√£o\n",
        "\n",
        "Existem v√°rias maneiras de avaliar o desempenho de uma empresa para decidir se √© v√°lido comprar a√ß√µes da mesma. Alguns m√©todos existentes s√£o:\n",
        "\n",
        "CAPM (Modelo de precifica√ß√£o de ativos de capital). √â um m√©todo que analise a rela√ß√£o entre o risco e o retorno que √© esperado de um investimento, obtido a partir de princ√≠pios de diversifica√ß√£o com pressupostos simplificados. Inicialmente √© irrealista (principalmente no Brasil).\n",
        "\n",
        "HME (Hip√≥tese do mercado eficiente). Essa hip√≥tese afirma que os mercados s√£o eficientes, ou seja, um agente n√£o consegue alcan√ßar consistentemente retornos superioers √† m√©dia do mercado, pois os pre√ßos dos ativos refletem toda a informa√ß√£o dispon√≠vel em um dado momento de tempo. √â importante citar que o mercado n√£o √© 100% racional.\n",
        "\n",
        "An√°lise t√©cnica. √â uma busca por padr√µes recorrentes e previs√≠veis nos pre√ßos do ativo. Esse m√©todo √© negado pelo HME.\n",
        "\n",
        "An√°lise Fundamentalista. Utiliza indicadores financeiros, de gest√£o, do neg√≥cio e do risco da empresa, al√©m de √≠ndices macroecon√¥micos na busca de determinar o valor presente descontado dos fluxos de caixa da empresa para chegar ao valor justo de cada a√ß√£o. Esse m√©todo √© quase todo negado pelo HME.\n",
        "\n",
        "## 1.2. Motiva√ß√£o\n",
        "\n",
        "Podemos usar outro m√©todo de avalia√ß√£o de empresas chamado Indice de Governan√ßa para definir conjuntos de empresas com boas governan√ßas. Empresas com boa governan√ßa tendem a lucrar.\n",
        "\n",
        "## 1.3. Import√¢ncia\n",
        "\n",
        "Esse novo modelo √© importante, pois agrupa as empresas em conjuntos(clusters) que tendem a ser semelhantes. Isso significa que quando uma empresa foi bem avaliada usando os m√©todos citados em Contextualiza√ß√£o (1.1), as outras empresas provavelmente tamb√©m v√£o ser bem avaliadas usando esses m√©todos.\n",
        "Ou seja, esse modelo nos ajudar√° a decidir se devemos ou n√£o comprar as a√ß√µes desse grupo de empresas.\n",
        "\n",
        "## 1.4. Abordagem anal√≠tica\n",
        "\n",
        "Vamos usar um algoritmo de MachineLearning para clusterizar as empresas.\n",
        "\n",
        "# 2. Hip√≥tese a ser investigada\n",
        "\n",
        "## 2.1. Objetivo geral\n",
        "\n",
        "Temos como objetivo obter conjuntos(clusters) que indicam empresas de boa governan√ßa.\n",
        "\n",
        "## 2.2. Etapas para atingir o objetivo\n",
        "\n",
        "Devemos\n",
        "1. Definir o problema\n",
        "2. Obter os dados\n",
        "3. Explorar os dados\n",
        "4. Preparar os dados\n",
        "5. Construir o modelo\n",
        "6. Avaliar o modelo\n",
        "\n",
        "## 2.3. Metodologia experimental\n",
        "\n",
        "# 3. Revis√£o bibliogr√°fica\n",
        "\n",
        "## 3.1 Duas refer√™ncias de artigos cient√≠ficos\n",
        "\n",
        "https://revistas.pucsp.br/rad/article/view/685\n",
        "https://periodicos.fgv.br/rbfin/article/view/1143\n",
        "\n",
        "\n",
        "## 3.2 Dois projetos semelhantes\n",
        "\n",
        "https://paperswithcode.com/method/k-means-clustering (achar outro)\n",
        "https://github.com/andymcdgeo/Andys_YouTube_Notebooks\n",
        "\n",
        "## 3.3 Como esses quatro est√£o inseridos no contexto do seu trabalho\n",
        "\n",
        "Os dois artigos comparam o indice de governan√ßa com a lucratividade da empresa. Os dois projetos ensinam a utilizar o algoritmo de clusteriza√ß√£o usando o k-means.\n",
        "\n",
        "# 4. Base de dados utilizada\n",
        "\n",
        "## 4.1. Porqu√™ essa base de dados √© adequada?\n",
        "\n",
        "Essa base de dados √© adequada pois ela nos diz as respostas das empresas em rela√ß√£o as 5 categorias de governan√ßa.\n",
        "\n",
        "## 4.2. Apresentar a base de dados\n",
        "\n",
        "Ser√£o extra√≠dos de https://github.com/Yurovskyy/sitedeploy/raw/gh-pages/docs/dataset_CGVN.xlsx?download=. Vou converter os mesmos para CSV e coloca-lo no github do trabalho atual.\n",
        "\n",
        "Como se trata de um algoritmo de clusteriza√ß√£o, n√£o precisamos de um dataset de teste.\n",
        "\n",
        "## 4.3. Detalhe a base de dados\n",
        "\n",
        "Como o arquivo origina pesava 100mb, n√£o foi poss√≠vel formatar o mesmo por meio desse notebook, pois isso exigiria que eu fizesse upload do arquivo no github, mas o github barra arquivos de serem enviados acima de 50mb.\n",
        "\n",
        "Por causa disso, criei um script local que retira as colunas do csv que eu n√£o preciso para esse algoritmo e fiz upload do csv formatado no github.\n",
        "\n",
        "> O script de limpeza usado se encontra no final do notebook. O script n√£o √© para ser executado.\n",
        "\n",
        "O dataset formatado est√° no seguinte link: https://github.com/Yurovskyy/CDD/blob/main/dataset_CGVN.csv\n",
        "\n",
        "No total, o dataset tem 115.722 entradas. Cada empresa em cada ano cont√©m 54 Itens (entradas), logo o total de Itens que ser√£o usados (Total das Prticas_adotadas) √© 2.143 üòÄ\n",
        "\n",
        "No dataset temos as seguintes colunas\n",
        "1. Data_Referencia\n",
        "2. Versao\n",
        "3. Nome_Empresarial\n",
        "4. ID_Item\n",
        "5. Pratica_Adotada\n",
        "\n",
        "### 1. Data_Referencia\n",
        "\n",
        "O item 1 refere-se a data em que as respostas foram colhidas. Algumas empresas mandam suas respostas desde 2018 (que √© a data de inicio do dataset), outras come√ßaram em 2019 por exemplo.\n",
        "\n",
        "Vamos avaliar a governan√ßa empresarial de cada ano caso a empresa tenha uma entrada por ano. Dessa maneira, podemos tamb√©m avaliar se a governan√ßa da empresa melhorou ou piorou com o passar do tempo.\n",
        "\n",
        "> Tecnicamente falando, vamos contatenar a data ao Nome_Empresarial para diferenciar a empresa no tempo\n",
        "\n",
        "### 2. Versao\n",
        "\n",
        "O item 2 refere-se a vers√£o das respostas. A empresa pode ter mandado uma resposta incompleta e ter submetido outra durante a data de entrega anual. Essa coluna n√£o √© relevante, pois sempre vamos considerar o resultado final.\n",
        "\n",
        "### 3. Nome_Empresarial\n",
        "\n",
        "O item 3 √© um item para identifica√ß√£o da empresa -nome da empresa - (juntamente com a Data_Referencia)\n",
        "\n",
        "### 4. ID_Item\n",
        "\n",
        "O item 4 refere-se ao item de governan√ßa. Cada item tem um texto o descrevendo, que pode ser encontrado no seguinte link\n",
        "\n",
        "https://yurovskyy.github.io/sitedeploy/\n",
        "\n",
        "(Clique em dados e depois em governan√ßa). A tabela no final da p√°gina cont√©m o ID_item e sua descri√ß√£o (Princ√≠pio e pr√°tica recomendada).\n",
        "\n",
        "### 5. Pratica_Adotada\n",
        "\n",
        "o item 5 √© o mais importante do dataset, pois nele temos a informa√ß√£o que queremos. Temos 4 **vari√°veis categ√≥ricas** condizentes as respostas das empresas de acordo com os ID_itens (item 4). Vamos realizar a seguinte transforma√ß√£o\n",
        "\n",
        "- Sim ‚Üí +1\n",
        "- N√£o ‚Üí -1\n",
        "- N√£o se aplica ‚Üí +0\n",
        "- Parcialmente ‚Üí +0,5\n",
        "\n",
        "Se a resposta da empresa √© sim, ela cumpre com a pr√°tica recomendada (ID_Item), se √© n√£o, ela n√£o cumpre.\n",
        "O N√£o se aplica se deve a empresas que essa pr√°tica n√£o faz sentido.\n",
        "O parcialmente √© um meio termo entre o sim e o n√£o\n",
        "\n",
        "> Em itera√ß√µes futuras do trabalho, acredito que devo trabalhar essa transforma√ß√£o de categ√≥ricas de uma forma mais aprofundada, pois o professor Marcos me disse que essa parte √© bem importante. Rumo aos dados perfeitos!\n",
        "> ### Perfect Data ‚Üí Perfect Model ‚Üí Perfect Results\n",
        "\n",
        "Como os dados j√° est√£o sendo trabalhados a algum tempo (artigo), n√£o existem valores faltantes üòÄ\n",
        "\n",
        "# 5. Utilize uma biblioteca de autoML para ter o resultado inicial\n",
        "\n",
        "## 5.1. Porqu√™ essa biblioteca?\n",
        "\n",
        "## 5.2. Qual √© a m√©trica de avalia√ß√£o utilizada?\n",
        "\n",
        "## 5.3. Apresente os resultados\n",
        "\n",
        "# 6. Discuss√£o e Considera√ß√µes finais\n",
        "\n",
        "## 6.1. Os resultados s√£o bons?\n",
        "\n",
        "## 6.2. Existe algum ganho em usar indicadores estat√≠ticos para os dados?\n",
        "\n",
        "## 6.3. A proposta √© adequada para ser utilizada ao longo do curso?"
      ],
      "metadata": {
        "id": "7w_FbUOskioB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 1.1.2. Motiva√ß√£o\n",
        "\n",
        "Todas as empresas tem uma certa governan√ßa. Se essa governan√ßa for verdadeiramente boa para a empresa, ela tender√° a lucrar. Podemos criar um modelo que cria conjunto de boas empresas para nos ajudar a escolher se devemos ou n√£o comprar a√ß√µes dessa empresa.\n",
        "\n",
        "### 1.1.3. Import√¢ncia\n",
        "\n",
        "Um dos problemas do HME √© que o ser humano n√£o √© 100% racional nas suas decis√µes, principalmente quando se trata de dinheiro. Esse modelo de machine learning pode ajudar o mercado a se tornar mais eficiente (racional).\n",
        "\n",
        "## 1.2. Abordagem\n",
        "\n",
        "Devemos ser capazes de clusterizar as empresas e de construir um modelo que clusteriza novas empresas automaticamente. A clusteriza√ß√£o √© uma cria√ß√£o de conjuntos n√£o definidos pelo usu√°rio, e sim pelo algoritmo de machine learning.\n",
        "\n",
        "> Isso √© bom, pois temos alguns modelos aprendidos em Engenharia Financeira como o CAPM e HME. Esse resultado teoricamente deve corroborar com esses modelos.\n",
        "\n",
        "\n",
        "#### 1.2.1. O chat-gpt fala isso sobre clusteriza√ß√£o:\n",
        "\n",
        "\n",
        "Clustering, ou clusteriza√ß√£o em portugu√™s, √© uma t√©cnica de aprendizado de m√°quina n√£o supervisionado que envolve a divis√£o de um conjunto de dados em grupos significativos, chamados de clusters. O objetivo √© agrupar itens de dados semelhantes em um mesmo cluster, enquanto itens de dados diferentes s√£o colocados em clusters distintos. A ideia √© encontrar estruturas intr√≠nsecas nos dados sem a necessidade de r√≥tulos ou categorias pr√©-definidas.\n",
        "\n",
        "Existem diferentes algoritmos de clusteriza√ß√£o, cada um com suas pr√≥prias abordagens e caracter√≠sticas. Os mais famosos s√£o: K-Means, DBSCAN, Hierarchical Clustering, Gaussian Mixture Models (GMM)\n",
        "\n",
        "### 1.2.2. M√©trica de desempenho\n",
        "\n",
        "Com base no √≠ndice de governan√ßa, podemos ter uma no√ß√£o de boas empresas. √â esperado que a clusteriza√ß√£o agrupe essas boas empresas que j√° s√£o conhecidas."
      ],
      "metadata": {
        "id": "nu9XBUu1Deg1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Obten√ß√£o dos dados\n",
        "\n",
        "Ser√£o extra√≠dos de https://yurovskyy.github.io/sitedeploy/. Vou converter os mesmos para CSV e coloca-lo no github do trabalho atual.\n",
        "\n",
        "Como se trata de um algoritmo de clusteriza√ß√£o, n√£o precisamos de um dataset de teste.\n",
        "\n",
        "#### 2.1.1. O chat-gpt fala isso sobre esse t√≥pico:\n",
        "\n",
        "Algoritmos de clusteriza√ß√£o n√£o s√£o tipicamente avaliados da mesma maneira que os algoritmos de aprendizado supervisionado, onde h√° um conjunto de dados de treinamento e um conjunto de dados de teste. Em vez disso, os algoritmos de clusteriza√ß√£o geralmente operam apenas no conjunto de dados dispon√≠vel para identificar padr√µes e agrupar os dados em clusters.\n",
        "\n",
        "Avaliar a qualidade dos clusters gerados por algoritmos de clusteriza√ß√£o √© uma tarefa subjetiva e muitas vezes depende do contexto espec√≠fico do problema e dos objetivos do projeto. Al√©m disso, a avalia√ß√£o pode envolver m√©todos como valida√ß√£o interna, valida√ß√£o externa ou at√© mesmo avalia√ß√£o visual.\n",
        "\n",
        "No entanto, √© poss√≠vel usar t√©cnicas de valida√ß√£o interna para avaliar a qualidade dos clusters gerados. Por exemplo, m√©tricas como a silhueta (silhouette score) podem ser usadas para avaliar a coes√£o intra-cluster e a separa√ß√£o inter-cluster dos dados. Essas m√©tricas podem ser calculadas usando apenas o conjunto de dados original sem a necessidade de um conjunto de dados de teste separado.\n",
        "\n",
        "√â importante observar que, embora os algoritmos de clusteriza√ß√£o n√£o usem explicitamente conjuntos de treinamento e teste, ainda √© poss√≠vel avaliar a estabilidade dos clusters gerados e a capacidade do algoritmo de generalizar para novos dados, dependendo da abordagem adotada para a avalia√ß√£o.\n",
        "\n",
        "### Ou seja, o que foi dito em m√©tricas (1. Defini√ß√£o do problema)\n",
        "\n",
        "## 2.1. Identificando os dados dispon√≠veis e necess√°rios\n",
        "\n",
        "Como o arquivo origina pesava 100mb, n√£o foi poss√≠vel formatar o mesmo por meio desse notebook, pois isso exigiria que eu fizesse upload do arquivo no github, mas o github barra arquivos de serem enviados acima de 50mb.\n",
        "\n",
        "Por causa disso, criei um script local que retira as colunas do csv que eu n√£o preciso para esse algoritmo e fiz upload do csv formatado no github.\n",
        "\n",
        "O dataset formatado est√° no seguinte link: https://github.com/Yurovskyy/CDD/blob/main/dataset_CGVN.csv\n",
        "\n",
        "O script de limpeza local est√° descrito abaixo:\n",
        "# **NAO EXECUTE ESSE SCRIPT, ELE √â UM EXEMPLO!**"
      ],
      "metadata": {
        "id": "Q70-ejqx4ANq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Explora√ß√£o dos dados\n",
        "\n",
        "Essa se√ß√£o depende muito do dataset que temos. Se fosse um algoritmo de ML de **Classifica√ß√£o** ou **Regress√£o**, ela seria mais importante.\n",
        "\n",
        "> Sobre a qualidade dos dados, acredito que posso mudar a vari√°vel categ√≥ria \"parcialmente\" para um valor decimal condizente com o seu impacto. Ser√° necess√°rio uma an√°lise minuciosa para isso. Depois que isso for feito, teremos os **dados perfeitos**.\n",
        "> ### Perfect Data ‚Üí Perfect Model ‚Üí Perfect Results\n",
        "\n",
        "No total, o dataset tem 115.723 entradas üòÄ\n",
        "\n",
        "\n",
        "## 3.1. Dicion√°rio de dados\n",
        "\n",
        "## 3.2. Tipos de cada vari√°vel\n",
        "\n",
        "## 3.3. Porcentagem de valores faltantes\n",
        "\n",
        "Como os dados j√° est√£o sendo trabalhados a algum tempo (artigo), n√£o existem valores faltantes üòÄ\n",
        "\n",
        "## 3.4. Distribui√ß√£o estat√≠stica dos dados\n",
        "\n"
      ],
      "metadata": {
        "id": "6nArgRRW5txJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Prepara√ß√£o dos dados\n",
        "\n",
        "Devemos formatar os dados para que os mesmos se adequem ao framework que vamos usar. Nesse caso vamos usar o H20, especificadamente o autoH20 com o **H20KMeansEstimator**\n",
        "\n",
        "https://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/modeling.html#h2okmeansestimator\n",
        "\n",
        "Esse link √© a documenta√ß√£o sobre o framework (m√≥dulo) H20."
      ],
      "metadata": {
        "id": "1UTNgFaA7bya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. 6. Constru√ß√£o do modelo e avalia√ß√£o\n",
        "\n",
        "Usaremos um autoML"
      ],
      "metadata": {
        "id": "ul3QR7dqIKHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h2o\n",
        "import h2o\n",
        "h2o.init()"
      ],
      "metadata": {
        "id": "GyjiMCzqPcZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# Carregar o arquivo CSV\n",
        "df = pd.read_csv('C:\\\\Users\\\\Yuri\\\\Desktop\\\\artigo\\\\backend\\\\novoscript\\\\results\\\\dataset_CGVN.csv',sep=\";\")\n",
        "\n",
        "# Selecionar as colunas necess√°rias\n",
        "colunas_desejadas = ['Data_Referencia', 'Versao', 'Nome_Empresarial', 'ID_Item', 'Pratica_Adotada']\n",
        "df = df[colunas_desejadas]\n",
        "\n",
        "# Salvar o arquivo CSV modificado\n",
        "df.to_csv('dataset_CGVN.csv', index=False)\n"
      ],
      "metadata": {
        "id": "AUrt1JvtZ7Ed"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}