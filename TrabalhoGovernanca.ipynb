{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOjuz3YIJPEZ4NKOjVyWPo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yurovskyy/CDD/blob/main/TrabalhoGovernanca.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Defini√ß√£o do problema\n",
        "\n",
        "## 1.1. Objetivo\n",
        "\n",
        "Devemos ser capazes de clusterizar as empresas e de construir um modelo que clusteriza novas empresas automaticamente. A clusteriza√ß√£o √© uma cria√ß√£o de conjuntos n√£o definidos pelo usu√°rio, e sim pelo algoritmo de machine learning.\n",
        "\n",
        "> Isso √© bom, pois temos alguns modelos aprendidos em Engenharia Financeira como o CAPM e HME. Esse resultado teoricamente deve corroborar com esses modelos.\n",
        "\n",
        "\n",
        "#### 1.1.1. O chat-gpt fala isso sobre clusteriza√ß√£o:\n",
        "\n",
        "\n",
        "Clustering, ou clusteriza√ß√£o em portugu√™s, √© uma t√©cnica de aprendizado de m√°quina n√£o supervisionado que envolve a divis√£o de um conjunto de dados em grupos significativos, chamados de clusters. O objetivo √© agrupar itens de dados semelhantes em um mesmo cluster, enquanto itens de dados diferentes s√£o colocados em clusters distintos. A ideia √© encontrar estruturas intr√≠nsecas nos dados sem a necessidade de r√≥tulos ou categorias pr√©-definidas.\n",
        "\n",
        "Existem diferentes algoritmos de clusteriza√ß√£o, cada um com suas pr√≥prias abordagens e caracter√≠sticas. Os mais famosos s√£o: K-Means, DBSCAN, Hierarchical Clustering, Gaussian Mixture Models (GMM)\n",
        "\n",
        "## 1.2. M√©trica de desempenho\n",
        "\n",
        "Com base no √≠ndice de governan√ßa, podemos ter uma no√ß√£o de boas empresas. √â esperado que a clusteriza√ß√£o agrupe essas boas empresas."
      ],
      "metadata": {
        "id": "nu9XBUu1Deg1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Obten√ß√£o dos dados\n",
        "\n",
        "Ser√£o extra√≠dos de https://yurovskyy.github.io/sitedeploy/. Vou converter os mesmos para CSV e coloca-lo no github do trabalho atual.\n",
        "\n",
        "Como se trata de um algoritmo de clusteriza√ß√£o, n√£o precisamos de um dataset de teste.\n",
        "\n",
        "#### 2.1.1. O chat-gpt fala isso sobre esse t√≥pico:\n",
        "\n",
        "Algoritmos de clusteriza√ß√£o n√£o s√£o tipicamente avaliados da mesma maneira que os algoritmos de aprendizado supervisionado, onde h√° um conjunto de dados de treinamento e um conjunto de dados de teste. Em vez disso, os algoritmos de clusteriza√ß√£o geralmente operam apenas no conjunto de dados dispon√≠vel para identificar padr√µes e agrupar os dados em clusters.\n",
        "\n",
        "Avaliar a qualidade dos clusters gerados por algoritmos de clusteriza√ß√£o √© uma tarefa subjetiva e muitas vezes depende do contexto espec√≠fico do problema e dos objetivos do projeto. Al√©m disso, a avalia√ß√£o pode envolver m√©todos como valida√ß√£o interna, valida√ß√£o externa ou at√© mesmo avalia√ß√£o visual.\n",
        "\n",
        "No entanto, √© poss√≠vel usar t√©cnicas de valida√ß√£o interna para avaliar a qualidade dos clusters gerados. Por exemplo, m√©tricas como a silhueta (silhouette score) podem ser usadas para avaliar a coes√£o intra-cluster e a separa√ß√£o inter-cluster dos dados. Essas m√©tricas podem ser calculadas usando apenas o conjunto de dados original sem a necessidade de um conjunto de dados de teste separado.\n",
        "\n",
        "√â importante observar que, embora os algoritmos de clusteriza√ß√£o n√£o usem explicitamente conjuntos de treinamento e teste, ainda √© poss√≠vel avaliar a estabilidade dos clusters gerados e a capacidade do algoritmo de generalizar para novos dados, dependendo da abordagem adotada para a avalia√ß√£o.\n",
        "\n",
        "### Ou seja, o que foi dito em m√©tricas (1. Defini√ß√£o do problema)\n",
        "\n",
        "## 2.1. Identificando os dados dispon√≠veis e necess√°rios\n",
        "\n",
        "Como o arquivo origina pesava 100mb, n√£o foi poss√≠vel formatar o mesmo por meio desse notebook, pois isso exigiria que eu fizesse upload do arquivo no github, mas o github barra arquivos de serem enviados acima de 50mb.\n",
        "\n",
        "Por causa disso, criei um script local que retira as colunas do csv que eu n√£o preciso para esse algoritmo e fiz upload do csv formatado no github.\n",
        "\n",
        "O dataset formatado est√° no seguinte link: https://github.com/Yurovskyy/CDD/blob/main/dataset_CGVN.csv\n",
        "\n",
        "O script de limpeza local est√° descrito abaixo:\n",
        "# **NAO EXECUTE ESSE SCRIPT, ELE √â UM EXEMPLO!**"
      ],
      "metadata": {
        "id": "Q70-ejqx4ANq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# Carregar o arquivo CSV\n",
        "df = pd.read_csv('C:\\\\Users\\\\Yuri\\\\Desktop\\\\artigo\\\\backend\\\\novoscript\\\\results\\\\dataset_CGVN.csv',sep=\";\")\n",
        "\n",
        "# Selecionar as colunas necess√°rias\n",
        "colunas_desejadas = ['Data_Referencia', 'Versao', 'Nome_Empresarial', 'ID_Item', 'Pratica_Adotada']\n",
        "df = df[colunas_desejadas]\n",
        "\n",
        "# Salvar o arquivo CSV modificado\n",
        "df.to_csv('dataset_CGVN.csv', index=False)\n"
      ],
      "metadata": {
        "id": "AUrt1JvtZ7Ed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Explora√ß√£o dos dados\n",
        "\n",
        "Essa se√ß√£o depende muito do dataset que temos. Se fosse um algoritmo de ML de **Classifica√ß√£o** ou **Regress√£o**, ela seria mais importante.\n",
        "\n",
        "> Sobre a qualidade dos dados, acredito que posso mudar a vari√°vel categ√≥ria \"parcialmente\" para um valor decimal condizente com o seu impacto. Ser√° necess√°rio uma an√°lise minuciosa para isso. Depois que isso for feito, teremos os **dados perfeitos**.\n",
        "> ### Perfect Data ‚Üí Perfect Model ‚Üí Perfect Results\n",
        "\n",
        "No total, o dataset tem 115.723 entradas üòÄ\n",
        "\n",
        "\n",
        "## 3.1. Dicion√°rio de dados\n",
        "\n",
        "## 3.2. Tipos de cada vari√°vel\n",
        "\n",
        "## 3.3. Porcentagem de valores faltantes\n",
        "\n",
        "Como os dados j√° est√£o sendo trabalhados a algum tempo (artigo), n√£o existem valores faltantes üòÄ\n",
        "\n",
        "## 3.4. Distribui√ß√£o estat√≠stica dos dados\n",
        "\n"
      ],
      "metadata": {
        "id": "6nArgRRW5txJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Prepara√ß√£o dos dados\n",
        "\n",
        "Devemos formatar os dados para que os mesmos se adequem ao framework que vamos usar. Nesse caso vamos usar o H20, especificadamente o autoH20 com o **H20KMeansEstimator**\n",
        "\n",
        "https://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/modeling.html#h2okmeansestimator\n",
        "\n",
        "Esse link √© a documenta√ß√£o sobre o framework (m√≥dulo) H20."
      ],
      "metadata": {
        "id": "1UTNgFaA7bya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. 6. Constru√ß√£o do modelo e avalia√ß√£o\n",
        "\n",
        "Usaremos um autoML"
      ],
      "metadata": {
        "id": "ul3QR7dqIKHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h2o\n",
        "import h2o\n",
        "h2o.init()"
      ],
      "metadata": {
        "id": "GyjiMCzqPcZa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}