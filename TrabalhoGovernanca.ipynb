{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM74shm5eR37K3LgeJCGxkY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yurovskyy/CDD/blob/main/TrabalhoGovernanca.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Formalização do problema\n",
        "\n",
        "## 1.1. Contextualização\n",
        "\n",
        "Existem várias maneiras de avaliar o desempenho de uma empresa para decidir se é válido comprar ações da mesma. Alguns métodos existentes são:\n",
        "\n",
        "CAPM (Modelo de precificação de ativos de capital). É um método que analise a relação entre o risco e o retorno que é esperado de um investimento, obtido a partir de princípios de diversificação com pressupostos simplificados. Inicialmente é irrealista (principalmente no Brasil).\n",
        "\n",
        "HME (Hipótese do mercado eficiente). Essa hipótese afirma que os mercados são eficientes, ou seja, um agente não consegue alcançar consistentemente retornos superioers à média do mercado, pois os preços dos ativos refletem toda a informação disponível em um dado momento de tempo. É importante citar que o mercado não é 100% racional.\n",
        "\n",
        "Análise técnica. É uma busca por padrões recorrentes e previsíveis nos preços do ativo. Esse método é negado pelo HME.\n",
        "\n",
        "Análise Fundamentalista. Utiliza indicadores financeiros, de gestão, do negócio e do risco da empresa, além de índices macroeconômicos na busca de determinar o valor presente descontado dos fluxos de caixa da empresa para chegar ao valor justo de cada ação. Esse método é quase todo negado pelo HME.\n",
        "\n",
        "## 1.2. Motivação\n",
        "\n",
        "Podemos usar outro método de avaliação de empresas chamado Indice de Governança para definir conjuntos de empresas com boas governanças. Empresas com boa governança tendem a lucrarem.\n",
        "\n",
        "## 1.3. Importância\n",
        "\n",
        "Esse novo método é importante, pois junta as empresas em conjuntos(clusters) que tendem a ser iguais. Isso significa que quando uma empresa foi bem avaliada usando os métodos citados em Contextualização (1.1), as outras empresas provavelmente também vão ser bem avaliadas usando esses métodos.\n",
        "\n",
        "## 1.4. Abordagem analítica\n",
        "\n",
        "Vamos usar um algoritmo de MachineLearning para clusterizar as empresas.\n",
        "\n",
        "# 2. Hipótese a ser investigada\n",
        "\n",
        "## 2.1. Objetivo geral\n",
        "\n",
        "Temos como objetivo obter conjuntos(clusters) que indicam empresas de boa governança.\n",
        "\n",
        "## 2.2. Etapas para atingir o objetivo\n",
        "\n",
        "Devemos\n",
        "1. Definir o problema\n",
        "2. Obter os dados\n",
        "3. Explorar os dados\n",
        "4. Preparar os dados\n",
        "5. Construir o modelo\n",
        "6. Avaliar o modelo\n",
        "\n",
        "## 2.3. Metodologia experimental\n",
        "\n",
        "# 3. Revisão bibliográfica\n",
        "\n",
        "## 3.1 Duas referências de artigos científicos\n",
        "\n",
        "https://revistas.pucsp.br/rad/article/view/685\n",
        "https://periodicos.fgv.br/rbfin/article/view/1143\n",
        "\n",
        "\n",
        "## 3.2 Dois projetos semelhantes\n",
        "\n",
        "https://paperswithcode.com/method/k-means-clustering\n",
        "\n",
        "\n",
        "## 3.3 Como esses quatro estão inseridos no contexto do seu trabalho\n",
        "\n",
        "# 4. Base de dados utilizada\n",
        "\n",
        "## 4.1. Porquê essa base de dados é adequada?\n",
        "\n",
        "## 4.2. Apresentar a base de dados\n",
        "\n",
        "## 4.3. Detalhe a base de dados\n",
        "\n",
        "# 5. Utilize uma biblioteca de autoML para ter o resultado inicial\n",
        "\n",
        "## 5.1. Porquê essa biblioteca?\n",
        "\n",
        "## 5.2. Qual é a métrica de avaliação utilizada?\n",
        "\n",
        "## 5.3. Apresente os resultados\n",
        "\n",
        "# 6. Discussão e Considerações finais\n",
        "\n",
        "## 6.1. Os resultados são bons?\n",
        "\n",
        "## 6.2. Existe algum ganho em usar indicadores estatíticos para os dados?\n",
        "\n",
        "## 6.3. A proposta é adequada para ser utilizada ao longo do curso?"
      ],
      "metadata": {
        "id": "7w_FbUOskioB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Definição do problema\n",
        "\n",
        "## 1.1. Objetivo\n",
        "\n",
        "### 1.1.1. Contextualização\n",
        "\n",
        "Existem várias maneiras de avaliar o desempenho de uma empresa para decidir se é válido comprar ações da mesma. Alguns métodos existentes são:\n",
        "\n",
        "CAPM (Modelo de precificação de ativos de capital). É um método que analise a relação entre o risco e o retorno que é esperado de um investimento, obtido a partir de princípios de diversificação com pressupostos simplificados. Inicialmente é irrealista (principalmente no Brasil).\n",
        "\n",
        "HME (Hipótese do mercado eficiente). Essa hipótese afirma que os mercados são eficientes, ou seja, um agente não consegue alcançar consistentemente retornos superioers à média do mercado, pois os preços dos ativos refletem toda a informação disponível em um dado momento de tempo. É importante citar que o mercado não é 100% racional.\n",
        "\n",
        "Análise técnica. É uma busca por padrões recorrentes e previsíveis nos preços do ativo. Esse método é negado pelo HME.\n",
        "\n",
        "Análise Fundamentalista. Utiliza indicadores financeiros, de gestão, do negócio e do risco da empresa, além de índices macroeconômicos na busca de determinar o valor presente descontado dos fluxos de caixa da empresa para chegar ao valor justo de cada ação. Esse método é quase todo negado pelo HME.\n",
        "\n",
        "### 1.1.2. Motivação\n",
        "\n",
        "Todas as empresas tem uma certa governança. Se essa governança for verdadeiramente boa para a empresa, ela tenderá a lucrar. Podemos criar um modelo que cria conjunto de boas empresas para nos ajudar a escolher se devemos ou não comprar ações dessa empresa.\n",
        "\n",
        "### 1.1.3. Importância\n",
        "\n",
        "Um dos problemas do HME é que o ser humano não é 100% racional nas suas decisões, principalmente quando se trata de dinheiro. Esse modelo de machine learning pode ajudar o mercado a se tornar mais eficiente (racional).\n",
        "\n",
        "## 1.2. Abordagem\n",
        "\n",
        "Devemos ser capazes de clusterizar as empresas e de construir um modelo que clusteriza novas empresas automaticamente. A clusterização é uma criação de conjuntos não definidos pelo usuário, e sim pelo algoritmo de machine learning.\n",
        "\n",
        "> Isso é bom, pois temos alguns modelos aprendidos em Engenharia Financeira como o CAPM e HME. Esse resultado teoricamente deve corroborar com esses modelos.\n",
        "\n",
        "\n",
        "#### 1.2.1. O chat-gpt fala isso sobre clusterização:\n",
        "\n",
        "\n",
        "Clustering, ou clusterização em português, é uma técnica de aprendizado de máquina não supervisionado que envolve a divisão de um conjunto de dados em grupos significativos, chamados de clusters. O objetivo é agrupar itens de dados semelhantes em um mesmo cluster, enquanto itens de dados diferentes são colocados em clusters distintos. A ideia é encontrar estruturas intrínsecas nos dados sem a necessidade de rótulos ou categorias pré-definidas.\n",
        "\n",
        "Existem diferentes algoritmos de clusterização, cada um com suas próprias abordagens e características. Os mais famosos são: K-Means, DBSCAN, Hierarchical Clustering, Gaussian Mixture Models (GMM)\n",
        "\n",
        "### 1.2.2. Métrica de desempenho\n",
        "\n",
        "Com base no índice de governança, podemos ter uma noção de boas empresas. É esperado que a clusterização agrupe essas boas empresas que já são conhecidas."
      ],
      "metadata": {
        "id": "nu9XBUu1Deg1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Obtenção dos dados\n",
        "\n",
        "Serão extraídos de https://yurovskyy.github.io/sitedeploy/. Vou converter os mesmos para CSV e coloca-lo no github do trabalho atual.\n",
        "\n",
        "Como se trata de um algoritmo de clusterização, não precisamos de um dataset de teste.\n",
        "\n",
        "#### 2.1.1. O chat-gpt fala isso sobre esse tópico:\n",
        "\n",
        "Algoritmos de clusterização não são tipicamente avaliados da mesma maneira que os algoritmos de aprendizado supervisionado, onde há um conjunto de dados de treinamento e um conjunto de dados de teste. Em vez disso, os algoritmos de clusterização geralmente operam apenas no conjunto de dados disponível para identificar padrões e agrupar os dados em clusters.\n",
        "\n",
        "Avaliar a qualidade dos clusters gerados por algoritmos de clusterização é uma tarefa subjetiva e muitas vezes depende do contexto específico do problema e dos objetivos do projeto. Além disso, a avaliação pode envolver métodos como validação interna, validação externa ou até mesmo avaliação visual.\n",
        "\n",
        "No entanto, é possível usar técnicas de validação interna para avaliar a qualidade dos clusters gerados. Por exemplo, métricas como a silhueta (silhouette score) podem ser usadas para avaliar a coesão intra-cluster e a separação inter-cluster dos dados. Essas métricas podem ser calculadas usando apenas o conjunto de dados original sem a necessidade de um conjunto de dados de teste separado.\n",
        "\n",
        "É importante observar que, embora os algoritmos de clusterização não usem explicitamente conjuntos de treinamento e teste, ainda é possível avaliar a estabilidade dos clusters gerados e a capacidade do algoritmo de generalizar para novos dados, dependendo da abordagem adotada para a avaliação.\n",
        "\n",
        "### Ou seja, o que foi dito em métricas (1. Definição do problema)\n",
        "\n",
        "## 2.1. Identificando os dados disponíveis e necessários\n",
        "\n",
        "Como o arquivo origina pesava 100mb, não foi possível formatar o mesmo por meio desse notebook, pois isso exigiria que eu fizesse upload do arquivo no github, mas o github barra arquivos de serem enviados acima de 50mb.\n",
        "\n",
        "Por causa disso, criei um script local que retira as colunas do csv que eu não preciso para esse algoritmo e fiz upload do csv formatado no github.\n",
        "\n",
        "O dataset formatado está no seguinte link: https://github.com/Yurovskyy/CDD/blob/main/dataset_CGVN.csv\n",
        "\n",
        "O script de limpeza local está descrito abaixo:\n",
        "# **NAO EXECUTE ESSE SCRIPT, ELE É UM EXEMPLO!**"
      ],
      "metadata": {
        "id": "Q70-ejqx4ANq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# Carregar o arquivo CSV\n",
        "df = pd.read_csv('C:\\\\Users\\\\Yuri\\\\Desktop\\\\artigo\\\\backend\\\\novoscript\\\\results\\\\dataset_CGVN.csv',sep=\";\")\n",
        "\n",
        "# Selecionar as colunas necessárias\n",
        "colunas_desejadas = ['Data_Referencia', 'Versao', 'Nome_Empresarial', 'ID_Item', 'Pratica_Adotada']\n",
        "df = df[colunas_desejadas]\n",
        "\n",
        "# Salvar o arquivo CSV modificado\n",
        "df.to_csv('dataset_CGVN.csv', index=False)\n"
      ],
      "metadata": {
        "id": "AUrt1JvtZ7Ed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Exploração dos dados\n",
        "\n",
        "Essa seção depende muito do dataset que temos. Se fosse um algoritmo de ML de **Classificação** ou **Regressão**, ela seria mais importante.\n",
        "\n",
        "> Sobre a qualidade dos dados, acredito que posso mudar a variável categória \"parcialmente\" para um valor decimal condizente com o seu impacto. Será necessário uma análise minuciosa para isso. Depois que isso for feito, teremos os **dados perfeitos**.\n",
        "> ### Perfect Data → Perfect Model → Perfect Results\n",
        "\n",
        "No total, o dataset tem 115.723 entradas 😀\n",
        "\n",
        "\n",
        "## 3.1. Dicionário de dados\n",
        "\n",
        "## 3.2. Tipos de cada variável\n",
        "\n",
        "## 3.3. Porcentagem de valores faltantes\n",
        "\n",
        "Como os dados já estão sendo trabalhados a algum tempo (artigo), não existem valores faltantes 😀\n",
        "\n",
        "## 3.4. Distribuição estatística dos dados\n",
        "\n"
      ],
      "metadata": {
        "id": "6nArgRRW5txJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Preparação dos dados\n",
        "\n",
        "Devemos formatar os dados para que os mesmos se adequem ao framework que vamos usar. Nesse caso vamos usar o H20, especificadamente o autoH20 com o **H20KMeansEstimator**\n",
        "\n",
        "https://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/modeling.html#h2okmeansestimator\n",
        "\n",
        "Esse link é a documentação sobre o framework (módulo) H20."
      ],
      "metadata": {
        "id": "1UTNgFaA7bya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. 6. Construção do modelo e avaliação\n",
        "\n",
        "Usaremos um autoML"
      ],
      "metadata": {
        "id": "ul3QR7dqIKHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h2o\n",
        "import h2o\n",
        "h2o.init()"
      ],
      "metadata": {
        "id": "GyjiMCzqPcZa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}